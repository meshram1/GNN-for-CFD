{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:33.528775Z",
     "start_time": "2026-02-13T05:50:33.523627Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "5acb04a1c8624e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:33.540954Z",
     "start_time": "2026-02-13T05:50:33.531964Z"
    }
   },
   "source": [
    "import pyvista as pv\n",
    "from matplotlib.style.core import library\n",
    "\n",
    "\n",
    "print(pv.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45.3\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "9d3d3024fd7fc2c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:33.622454Z",
     "start_time": "2026-02-13T05:50:33.551694Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from data_processor import sorted_vtk\n",
    "\"\"\"files = sorted(glob.glob(\"VTK/cavity_*.vtk\"), key = lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "files_2 = sorted(glob.glob(\"VTK_Uin1_Re1000/cavity_*.vtk\"), key = lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "print(f\"{len(files_2)} files!\")\"\"\"\n",
    "\n",
    "cases = [\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin0_1_Re100/cavity_*.vtk\"), \"global_attr\": [0.1, 100.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin0_5_Re50/cavity_*.vtk\"), \"global_attr\": [0.5, 50.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_5_Re150/cavity_*.vtk\"), \"global_attr\": [1.5, 150.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_5_Re1500/cavity_*.vtk\"), \"global_attr\": [1.5, 1500.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_25_Re1250/cavity_*.vtk\"), \"global_attr\": [1.25, 1250.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_Re100/cavity_*.vtk\"), \"global_attr\": [1.0, 100.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_Re1000/cavity_*.vtk\"), \"global_attr\": [1.0, 1000.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin2_0_Re200/cavity_*.vtk\"), \"global_attr\": [2.0, 200.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin0_05_Re10/cavity_*.vtk\"), \"global_attr\": [0.05, 10.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin4_Re100/cavity_*.vtk\"), \"global_attr\": [4.0, 100.0]}\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "64ecf786b7b4ac48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:33.634796Z",
     "start_time": "2026-02-13T05:50:33.628930Z"
    }
   },
   "source": [
    "import importlib\n",
    "import get_node_info\n",
    "importlib.reload(get_node_info)\n",
    "from get_node_info import get_fluid_prop"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyvista version used: 0.45.3\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "08297e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:33.651445Z",
     "start_time": "2026-02-13T05:50:33.648258Z"
    }
   },
   "source": [
    "\n",
    "step = 100\n",
    "from transformations import normalize_fluid_data\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "a8062119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:33.686502Z",
     "start_time": "2026-02-13T05:50:33.657301Z"
    }
   },
   "source": [
    "mesh = pv.read(\"VTK_Uin1_Re1000/cavity_0.vtk\")\n",
    "cell_cent = mesh.cell_centers()\n",
    "cell_ID = mesh.cell_data[\"cellID\"].astype(np.int64)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "b1a2dafd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:33.697754Z",
     "start_time": "2026-02-13T05:50:33.691094Z"
    }
   },
   "source": [
    "pts = cell_cent.points\n",
    "x = pts[:, 0]\n",
    "y = pts[:, 1]\n",
    "z = pts[:, 2]\n",
    "# on an unstructured grid cell centered we use interpolation to get the values of the variables at the grid instead of using the cell centered values.\n",
    "\n",
    "cell_data = np.column_stack([cell_ID, x, y, z])\n",
    "n_cells = np.shape(cell_data)[0]\n",
    "xy = np.column_stack([x, y])"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "cb69dd6c836ecc86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:50:39.659239Z",
     "start_time": "2026-02-13T05:50:33.703014Z"
    }
   },
   "source": [
    "from edge_info import edges_from_faces\n",
    "from edge_info import build_edge_feature\n",
    "\n",
    "edge_info = edges_from_faces(mesh)\n",
    "edge_attribute = build_edge_feature(mesh, edge_info)\n",
    "# distance from edge to edge is used as feature"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-02-13T05:50:39.664454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_processor import GraphDataset\n",
    "\n",
    "edge_index = torch.tensor(edge_info.T, dtype=torch.long)\n",
    "edge_attr = torch.tensor(edge_attribute, dtype=torch.float32)\n",
    "xy = torch.tensor(xy, dtype=torch.float32)\n",
    "dataset = GraphDataset(cases, xy, edge_info, edge_attribute, step, normalize_fluid_data)"
   ],
   "id": "bb7d1c8adfa1b881",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.152628Z",
     "start_time": "2026-02-13T05:32:39.143059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\"\"\"\n",
    "# node features: shape (N, F)\n",
    "x_train = torch.tensor(node_data, dtype=torch.float32)\n",
    "x_test = torch.tensor(node_data_next, dtype=torch.float32)\n",
    "\n",
    "# edges: your edge_info is shape (E, 2)\n",
    "edge_index = torch.tensor(edge_info.T, dtype=torch.long)   # (2, E)\n",
    "\n",
    "# edge features: shape (E, 3)\n",
    "edge_attr = torch.tensor(edge_attribute, dtype=torch.float32)\n",
    "global_attr_train = torch.tensor([1,100], dtype=torch.float32)\n",
    "global_attr_test = torch.tensor([1,1000], dtype=torch.float32)\n",
    "data = Data(x=x_train, edge_index=edge_index, edge_attr=edge_attr,global_attr=global_attr_train)\n",
    "data_plus = Data(x=x_test, edge_index=edge_index, edge_attr=edge_attr, global_attr=global_attr_test)\n",
    "np.shape(edge_attr)\"\"\""
   ],
   "id": "362904818e1503b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# node features: shape (N, F)\\nx_train = torch.tensor(node_data, dtype=torch.float32)\\nx_test = torch.tensor(node_data_next, dtype=torch.float32)\\n\\n# edges: your edge_info is shape (E, 2)\\nedge_index = torch.tensor(edge_info.T, dtype=torch.long)   # (2, E)\\n\\n# edge features: shape (E, 3)\\nedge_attr = torch.tensor(edge_attribute, dtype=torch.float32)\\nglobal_attr_train = torch.tensor([1,100], dtype=torch.float32)\\nglobal_attr_test = torch.tensor([1,1000], dtype=torch.float32)\\ndata = Data(x=x_train, edge_index=edge_index, edge_attr=edge_attr,global_attr=global_attr_train)\\ndata_plus = Data(x=x_test, edge_index=edge_index, edge_attr=edge_attr, global_attr=global_attr_test)\\nnp.shape(edge_attr)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.199891Z",
     "start_time": "2026-02-13T05:32:39.194871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ],
   "id": "7c24281b5b2877cf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.210702Z",
     "start_time": "2026-02-13T05:32:39.206183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_degree(data):\n",
    "    N = data.num_nodes\n",
    "    src = data.edge_index[0]\n",
    "    deg = torch.bincount(src, minlength=N).float()  # out-degree\n",
    "    pos = data.x[:, :2].cpu().numpy()\n",
    "    deg_np = deg.numpy()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(pos[:,0], pos[:,1], c=deg_np, s=2)\n",
    "    plt.gca().set_aspect('equal', 'box')\n",
    "    plt.title(\"Node out-degree (should be ~3 interior, lower near boundaries)\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ],
   "id": "3a31b26ac5335765",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.222539Z",
     "start_time": "2026-02-13T05:32:39.217433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)"
   ],
   "id": "bcb2d37d20ca3d3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.244831Z",
     "start_time": "2026-02-13T05:32:39.236250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class PoolModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # Initial Graph Convolution\n",
    "        self.conv1 = GCNConv(data.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # Regression head to predict your CFD values (e.g., Ux, Uy, P)\n",
    "        self.out = torch.nn.Linear(hidden_channels, 5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 1. Obtain node embeddings\n",
    "\n",
    "        x, edge_index= data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # 2. Node-level output (for the full 50,480 vector prediction)\n",
    "        return self.out(x)"
   ],
   "id": "db9988f3e1ff9580",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.262209Z",
     "start_time": "2026-02-13T05:32:39.256910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PoolModel(64).to(device)\n",
    "data = data.to(device)\n",
    "data_plus = data_plus.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "total_loss = 0\n",
    "for epoch in range(100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.mse_loss(out, data_plus.x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = total_loss / (epoch+1)\n",
    "    print(f\"Epoch {epoch+1:03d} | Average Loss: {avg_loss:.6f}\")\"\"\""
   ],
   "id": "a00c1b588f87cd6b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\nmodel = PoolModel(64).to(device)\\ndata = data.to(device)\\ndata_plus = data_plus.to(device)\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\\n\\nmodel.train()\\ntotal_loss = 0\\nfor epoch in range(100):\\n\\n    optimizer.zero_grad()\\n    out = model(data)\\n    loss = F.mse_loss(out, data_plus.x)\\n    loss.backward()\\n    optimizer.step()\\n    total_loss += loss.item()\\n\\n    # Print average loss for the epoch\\n    avg_loss = total_loss / (epoch+1)\\n    print(f\"Epoch {epoch+1:03d} | Average Loss: {avg_loss:.6f}\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.286621Z",
     "start_time": "2026-02-13T05:32:39.280023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GNNMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_input, edge_in, hidden_channels, global_att_dim):\n",
    "        super(GNNMessagePassing, self).__init__(aggr='add')\n",
    "\n",
    "        self.msg_mlp = Sequential(\n",
    "            nn.Linear(2*hidden_channels + edge_in + global_att_dim, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.upd_mlp = Sequential(\n",
    "            nn.Linear(2*hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, global_attr):\n",
    "        if global_attr.dim() == 2:\n",
    "            global_attr = global_attr.squeeze(0)  # [G]\n",
    "\n",
    "        E = edge_attr.size(0)  # 150998\n",
    "        g_edge = global_attr.unsqueeze(0).expand(E, -1)\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr,global_attr=g_edge)\n",
    "\n",
    "    def message(self,x_i, x_j,edge_attr,global_attr):\n",
    "        combined = torch.cat([x_i, x_j, edge_attr, global_attr], dim=-1)\n",
    "        return self.msg_mlp(combined)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        combined = torch.cat([x, aggr_out], dim=-1)\n",
    "        return self.upd_mlp(combined)"
   ],
   "id": "e6f1b7364b5b3000",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:39.316365Z",
     "start_time": "2026-02-13T05:32:39.310377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#using the message passing model\n",
    "\n",
    "class FlowPredictor(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels,num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = 10\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            self.layers.append(GNNMessagePassing(node_input=hidden_channels, edge_in=3, hidden_channels=hidden_channels, global_att_dim=2)) ## what sort of layers do we have in our module list.\n",
    "        self.encoder = nn.Linear(5, hidden_channels) # [x, y, u, v, p] -> 64\n",
    "#        self.processor = GNNMessagePassing(node_input=hidden_channels, edge_in=3, hidden_channels=hidden_channels)\n",
    "        self.decoder = nn.Linear(hidden_channels, 5) # hidden_channels -> [x, y, u, v, p]\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.encoder(data.x)\n",
    "        for layer in self.layers:\n",
    "            h_update = layer(h, data.edge_index, data.edge_attr, data.global_attr)\n",
    "            print(h_update)\n",
    "\n",
    "        h = h + h_update\n",
    "        return self.decoder(h)\n",
    "\n",
    "    print(edge_attr.size())"
   ],
   "id": "6e1e56742bffd085",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150998, 3])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T05:32:40.937915Z",
     "start_time": "2026-02-13T05:32:39.331799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FlowPredictor(hidden_channels=64,num_layers=10).to(device)\n",
    "#data = data.to(device)\n",
    "#data_plus = data_plus.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "total_loss = 0\n",
    "total_samples = len(loader.dataset)\n",
    "print(total_samples)\n",
    "for epoch in range(100):\n",
    "    for batch_idx in loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch_idx = batch_idx.to(device)\n",
    "        output, latent = model(batch_idx)\n",
    "        loss = F.mse_loss(output, batch_idx)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:03d} | Average Loss: {avg_loss:.6f}\")\n"
   ],
   "id": "1fe7b9804882e40a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "xy: <class 'torch.Tensor'> torch.Size([50480, 2]) torch.float32\n",
      "uvp: <class 'torch.Tensor'> torch.Size([50480, 3]) torch.float32\n",
      "xy: <class 'torch.Tensor'> torch.Size([50480, 2]) torch.float32\n",
      "uvp: <class 'torch.Tensor'> torch.Size([50480, 3]) torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (301996x135 and 133x64)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     13\u001B[39m optimizer.zero_grad()\n\u001B[32m     14\u001B[39m batch_idx = batch_idx.to(device)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m output, latent = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m loss = F.mse_loss(output, batch_idx)\n\u001B[32m     17\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mFlowPredictor.forward\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m     16\u001B[39m h = \u001B[38;5;28mself\u001B[39m.encoder(data.x)\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.layers:\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     h_update = \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mglobal_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28mprint\u001B[39m(h_update)\n\u001B[32m     21\u001B[39m h = h + h_update\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 22\u001B[39m, in \u001B[36mGNNMessagePassing.forward\u001B[39m\u001B[34m(self, x, edge_index, edge_attr, global_attr)\u001B[39m\n\u001B[32m     20\u001B[39m E = edge_attr.size(\u001B[32m0\u001B[39m)  \u001B[38;5;66;03m# 150998\u001B[39;00m\n\u001B[32m     21\u001B[39m g_edge = global_attr.unsqueeze(\u001B[32m0\u001B[39m).expand(E, -\u001B[32m1\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m=\u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43mglobal_attr\u001B[49m\u001B[43m=\u001B[49m\u001B[43mg_edge\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:523\u001B[39m, in \u001B[36mMessagePassing.propagate\u001B[39m\u001B[34m(self, edge_index, size, **kwargs)\u001B[39m\n\u001B[32m    521\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    522\u001B[39m         msg_kwargs = res[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[32m--> \u001B[39m\u001B[32m523\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    524\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._message_forward_hooks.values():\n\u001B[32m    525\u001B[39m     res = hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 26\u001B[39m, in \u001B[36mGNNMessagePassing.message\u001B[39m\u001B[34m(self, x_i, x_j, edge_attr, global_attr)\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmessage\u001B[39m(\u001B[38;5;28mself\u001B[39m,x_i, x_j,edge_attr,global_attr):\n\u001B[32m     25\u001B[39m     combined = torch.cat([x_i, x_j, edge_attr, global_attr], dim=-\u001B[32m1\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmsg_mlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcombined\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    248\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    249\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    251\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\PythonProject\\.venv1\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (301996x135 and 133x64)"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"lets put the model on eval mode now\"\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data_plus.y = data.x[:, 2:5].clone()\n",
    "    x_in = data_plus.x.clone()\n",
    "    x_in[:, 2:5] = 0.0\n",
    "\n",
    "    data_test_in = data_plus.clone()\n",
    "    data_test_in.x = x_in\n",
    "    data_test_in.global_attr = torch.tensor([1, 1000], device=device).float()\n",
    "\n",
    "    pred = model(data_test_in)\n",
    "\n",
    "test_loss = F.mse_loss(pred[:, 2:5], data_plus.y).item()\n",
    "rel = torch.norm(pred[:,2:5] - data_plus.y) / torch.norm(data_plus.y)\n",
    "print(\"Relative L2 error:\", rel.item())\n",
    "print(\"test mse:\", test_loss)"
   ],
   "id": "8c12ea6f9b8d39e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "30e9cf51e57dccca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

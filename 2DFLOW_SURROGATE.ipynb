{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-10T15:16:16.130171Z",
     "start_time": "2026-02-10T15:16:09.246508Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5acb04a1c8624e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:16:18.866220Z",
     "start_time": "2026-02-10T15:16:18.061184Z"
    }
   },
   "source": [
    "import pyvista as pv\n",
    "from matplotlib.style.core import library\n",
    "\n",
    "\n",
    "print(pv.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45.3\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9d3d3024fd7fc2c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:18:39.245011Z",
     "start_time": "2026-02-10T15:18:39.221401Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from data_processor import sorted_vtk\n",
    "\"\"\"files = sorted(glob.glob(\"VTK/cavity_*.vtk\"), key = lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "files_2 = sorted(glob.glob(\"VTK_Uin1_Re1000/cavity_*.vtk\"), key = lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "print(f\"{len(files_2)} files!\")\"\"\"\n",
    "\n",
    "cases = [\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin0_1_Re100/cavity_*.vtk\"), \"global_attr\": [0.1, 100.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin0_5_Re50/cavity_*.vtk\"), \"global_attr\": [0.5, 50.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_5_Re150/cavity_*.vtk\"), \"global_attr\": [1.5, 150.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_5_Re1500/cavity_*.vtk\"), \"global_attr\": [1.5, 1500.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_25_Re1250/cavity_*.vtk\"), \"global_attr\": [1.25, 1250.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_Re100/cavity_*.vtk\"), \"global_attr\": [1.0, 100.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_Re1000/cavity_*.vtk\"), \"global_attr\": [1.0, 1000.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin1_Re1000/cavity_*.vtk\"), \"global_attr\": [1.0, 1000.0]},\n",
    "    {\"files\": sorted_vtk(\"VTK_Uin0_05_Re10/cavity_*.vtk\"), \"global_attr\": [0.05, 10.0]},\n",
    "]\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "64ecf786b7b4ac48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:18:42.565692Z",
     "start_time": "2026-02-10T15:18:42.560556Z"
    }
   },
   "source": [
    "import importlib\n",
    "import get_node_info\n",
    "importlib.reload(get_node_info)\n",
    "from get_node_info import get_fluid_prop"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyvista version used: 0.45.3\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "08297e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:20:21.710361Z",
     "start_time": "2026-02-10T15:20:21.706648Z"
    }
   },
   "source": [
    "\n",
    "step = 100\n",
    "from transformations import normalize_fluid_data\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a8062119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:22:05.298166Z",
     "start_time": "2026-02-10T15:22:05.247647Z"
    }
   },
   "source": [
    "mesh = pv.read(\"VTK_Uin1_Re1000/cavity_0.vtk\")\n",
    "cell_cent = mesh.cell_centers()\n",
    "cell_ID = mesh.cell_data[\"cellID\"].astype(np.int64)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "b1a2dafd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:22:06.644281Z",
     "start_time": "2026-02-10T15:22:06.638561Z"
    }
   },
   "source": [
    "pts = cell_cent.points\n",
    "x = pts[:, 0]\n",
    "y = pts[:, 1]\n",
    "z = pts[:, 2]\n",
    "# on an unstructured grid cell centered we use interpolation to get the values of the variables at the grid instead of using the cell centered values.\n",
    "\n",
    "cell_data = np.column_stack([cell_ID, x, y, z])\n",
    "n_cells = np.shape(cell_data)[0]\n",
    "xy = np.column_stack([x, y])"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "cb69dd6c836ecc86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:22:15.258506Z",
     "start_time": "2026-02-10T15:22:09.056491Z"
    }
   },
   "source": [
    "from edge_info import edges_from_faces\n",
    "from edge_info import build_edge_feature\n",
    "\n",
    "edge_info = edges_from_faces(mesh)\n",
    "edge_attribute = build_edge_feature(mesh, edge_info)\n",
    "# distance from edge to edge is used as feature"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:25:48.506886Z",
     "start_time": "2026-02-10T15:24:41.565659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_processor import GraphDataset\n",
    "\n",
    "edge_index = torch.tensor(edge_info.T, dtype=torch.long)\n",
    "edge_attr = torch.tensor(edge_attribute, dtype=torch.float32)\n",
    "xy = torch.tensor(xy, dtype=torch.float32)\n",
    "dataset = GraphDataset(cases, xy, edge_info, edge_attribute, step, normalize_fluid_data)"
   ],
   "id": "bb7d1c8adfa1b881",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:25:53.265401Z",
     "start_time": "2026-02-10T15:25:53.258156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\"\"\"\n",
    "# node features: shape (N, F)\n",
    "x_train = torch.tensor(node_data, dtype=torch.float32)\n",
    "x_test = torch.tensor(node_data_next, dtype=torch.float32)\n",
    "\n",
    "# edges: your edge_info is shape (E, 2)\n",
    "edge_index = torch.tensor(edge_info.T, dtype=torch.long)   # (2, E)\n",
    "\n",
    "# edge features: shape (E, 3)\n",
    "edge_attr = torch.tensor(edge_attribute, dtype=torch.float32)\n",
    "global_attr_train = torch.tensor([1,100], dtype=torch.float32)\n",
    "global_attr_test = torch.tensor([1,1000], dtype=torch.float32)\n",
    "data = Data(x=x_train, edge_index=edge_index, edge_attr=edge_attr,global_attr=global_attr_train)\n",
    "data_plus = Data(x=x_test, edge_index=edge_index, edge_attr=edge_attr, global_attr=global_attr_test)\n",
    "np.shape(edge_attr)\"\"\""
   ],
   "id": "362904818e1503b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# node features: shape (N, F)\\nx_train = torch.tensor(node_data, dtype=torch.float32)\\nx_test = torch.tensor(node_data_next, dtype=torch.float32)\\n\\n# edges: your edge_info is shape (E, 2)\\nedge_index = torch.tensor(edge_info.T, dtype=torch.long)   # (2, E)\\n\\n# edge features: shape (E, 3)\\nedge_attr = torch.tensor(edge_attribute, dtype=torch.float32)\\nglobal_attr_train = torch.tensor([1,100], dtype=torch.float32)\\nglobal_attr_test = torch.tensor([1,1000], dtype=torch.float32)\\ndata = Data(x=x_train, edge_index=edge_index, edge_attr=edge_attr,global_attr=global_attr_train)\\ndata_plus = Data(x=x_test, edge_index=edge_index, edge_attr=edge_attr, global_attr=global_attr_test)\\nnp.shape(edge_attr)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:25:56.836396Z",
     "start_time": "2026-02-10T15:25:56.831691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ],
   "id": "7c24281b5b2877cf",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:26:39.453904Z",
     "start_time": "2026-02-10T15:26:39.448765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_degree(data):\n",
    "    N = data.num_nodes\n",
    "    src = data.edge_index[0]\n",
    "    deg = torch.bincount(src, minlength=N).float()  # out-degree\n",
    "    pos = data.x[:, :2].cpu().numpy()\n",
    "    deg_np = deg.numpy()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(pos[:,0], pos[:,1], c=deg_np, s=2)\n",
    "    plt.gca().set_aspect('equal', 'box')\n",
    "    plt.title(\"Node out-degree (should be ~3 interior, lower near boundaries)\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ],
   "id": "3a31b26ac5335765",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T15:27:01.184344Z",
     "start_time": "2026-02-10T15:27:01.181057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)"
   ],
   "id": "bcb2d37d20ca3d3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T15:22:47.169169Z",
     "start_time": "2026-02-06T15:22:47.162111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class PoolModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # Initial Graph Convolution\n",
    "        self.conv1 = GCNConv(data.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # Regression head to predict your CFD values (e.g., Ux, Uy, P)\n",
    "        self.out = torch.nn.Linear(hidden_channels, 5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # 1. Obtain node embeddings\n",
    "\n",
    "        x, edge_index= data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # 2. Node-level output (for the full 50,480 vector prediction)\n",
    "        return self.out(x)"
   ],
   "id": "db9988f3e1ff9580",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:42:12.412410Z",
     "start_time": "2026-02-05T14:42:10.674695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PoolModel(64).to(device)\n",
    "data = data.to(device)\n",
    "data_plus = data_plus.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "total_loss = 0\n",
    "for epoch in range(100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.mse_loss(out, data_plus.x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = total_loss / (epoch+1)\n",
    "    print(f\"Epoch {epoch+1:03d} | Average Loss: {avg_loss:.6f}\")"
   ],
   "id": "a00c1b588f87cd6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Average Loss: 19.142281\n",
      "Epoch 002 | Average Loss: 15.619940\n",
      "Epoch 003 | Average Loss: 12.582310\n",
      "Epoch 004 | Average Loss: 10.044832\n",
      "Epoch 005 | Average Loss: 8.338594\n",
      "Epoch 006 | Average Loss: 7.557105\n",
      "Epoch 007 | Average Loss: 7.029432\n",
      "Epoch 008 | Average Loss: 6.414405\n",
      "Epoch 009 | Average Loss: 5.779824\n",
      "Epoch 010 | Average Loss: 5.243947\n",
      "Epoch 011 | Average Loss: 4.851149\n",
      "Epoch 012 | Average Loss: 4.572845\n",
      "Epoch 013 | Average Loss: 4.354673\n",
      "Epoch 014 | Average Loss: 4.153587\n",
      "Epoch 015 | Average Loss: 3.948625\n",
      "Epoch 016 | Average Loss: 3.738371\n",
      "Epoch 017 | Average Loss: 3.535659\n",
      "Epoch 018 | Average Loss: 3.357446\n",
      "Epoch 019 | Average Loss: 3.210498\n",
      "Epoch 020 | Average Loss: 3.086726\n",
      "Epoch 021 | Average Loss: 2.970985\n",
      "Epoch 022 | Average Loss: 2.853662\n",
      "Epoch 023 | Average Loss: 2.736168\n",
      "Epoch 024 | Average Loss: 2.625820\n",
      "Epoch 025 | Average Loss: 2.528257\n",
      "Epoch 026 | Average Loss: 2.442387\n",
      "Epoch 027 | Average Loss: 2.363633\n",
      "Epoch 028 | Average Loss: 2.288484\n",
      "Epoch 029 | Average Loss: 2.215801\n",
      "Epoch 030 | Average Loss: 2.145894\n",
      "Epoch 031 | Average Loss: 2.079829\n",
      "Epoch 032 | Average Loss: 2.018599\n",
      "Epoch 033 | Average Loss: 1.961934\n",
      "Epoch 034 | Average Loss: 1.908610\n",
      "Epoch 035 | Average Loss: 1.857486\n",
      "Epoch 036 | Average Loss: 1.807991\n",
      "Epoch 037 | Average Loss: 1.760353\n",
      "Epoch 038 | Average Loss: 1.715202\n",
      "Epoch 039 | Average Loss: 1.672822\n",
      "Epoch 040 | Average Loss: 1.632994\n",
      "Epoch 041 | Average Loss: 1.595203\n",
      "Epoch 042 | Average Loss: 1.558872\n",
      "Epoch 043 | Average Loss: 1.523717\n",
      "Epoch 044 | Average Loss: 1.489847\n",
      "Epoch 045 | Average Loss: 1.457459\n",
      "Epoch 046 | Average Loss: 1.426635\n",
      "Epoch 047 | Average Loss: 1.397231\n",
      "Epoch 048 | Average Loss: 1.368932\n",
      "Epoch 049 | Average Loss: 1.341547\n",
      "Epoch 050 | Average Loss: 1.315093\n",
      "Epoch 051 | Average Loss: 1.289681\n",
      "Epoch 052 | Average Loss: 1.265381\n",
      "Epoch 053 | Average Loss: 1.242095\n",
      "Epoch 054 | Average Loss: 1.219634\n",
      "Epoch 055 | Average Loss: 1.197874\n",
      "Epoch 056 | Average Loss: 1.176787\n",
      "Epoch 057 | Average Loss: 1.156409\n",
      "Epoch 058 | Average Loss: 1.136769\n",
      "Epoch 059 | Average Loss: 1.117816\n",
      "Epoch 060 | Average Loss: 1.099469\n",
      "Epoch 061 | Average Loss: 1.081668\n",
      "Epoch 062 | Average Loss: 1.064398\n",
      "Epoch 063 | Average Loss: 1.047684\n",
      "Epoch 064 | Average Loss: 1.031523\n",
      "Epoch 065 | Average Loss: 1.015875\n",
      "Epoch 066 | Average Loss: 1.000687\n",
      "Epoch 067 | Average Loss: 0.985917\n",
      "Epoch 068 | Average Loss: 0.971558\n",
      "Epoch 069 | Average Loss: 0.957616\n",
      "Epoch 070 | Average Loss: 0.944082\n",
      "Epoch 071 | Average Loss: 0.930935\n",
      "Epoch 072 | Average Loss: 0.918142\n",
      "Epoch 073 | Average Loss: 0.905683\n",
      "Epoch 074 | Average Loss: 0.893554\n",
      "Epoch 075 | Average Loss: 0.881751\n",
      "Epoch 076 | Average Loss: 0.870267\n",
      "Epoch 077 | Average Loss: 0.859080\n",
      "Epoch 078 | Average Loss: 0.848172\n",
      "Epoch 079 | Average Loss: 0.837530\n",
      "Epoch 080 | Average Loss: 0.827150\n",
      "Epoch 081 | Average Loss: 0.817030\n",
      "Epoch 082 | Average Loss: 0.807159\n",
      "Epoch 083 | Average Loss: 0.797525\n",
      "Epoch 084 | Average Loss: 0.788115\n",
      "Epoch 085 | Average Loss: 0.778922\n",
      "Epoch 086 | Average Loss: 0.769943\n",
      "Epoch 087 | Average Loss: 0.761172\n",
      "Epoch 088 | Average Loss: 0.752601\n",
      "Epoch 089 | Average Loss: 0.744219\n",
      "Epoch 090 | Average Loss: 0.736021\n",
      "Epoch 091 | Average Loss: 0.728001\n",
      "Epoch 092 | Average Loss: 0.720156\n",
      "Epoch 093 | Average Loss: 0.712481\n",
      "Epoch 094 | Average Loss: 0.704967\n",
      "Epoch 095 | Average Loss: 0.697610\n",
      "Epoch 096 | Average Loss: 0.690405\n",
      "Epoch 097 | Average Loss: 0.683349\n",
      "Epoch 098 | Average Loss: 0.676437\n",
      "Epoch 099 | Average Loss: 0.669664\n",
      "Epoch 100 | Average Loss: 0.663025\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T15:22:56.613490Z",
     "start_time": "2026-02-06T15:22:56.607131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GNNMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_input, edge_in, hidden_channels, global_att_dim):\n",
    "        super(GNNMessagePassing, self).__init__(aggr='add')\n",
    "\n",
    "        self.msg_mlp = Sequential(\n",
    "            nn.Linear(2*hidden_channels + edge_in + global_att_dim, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "        self.upd_mlp = Sequential(\n",
    "            nn.Linear(2*hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, global_attr):\n",
    "        if global_attr.dim() == 2:\n",
    "            global_attr = global_attr.squeeze(0)  # [G]\n",
    "\n",
    "        E = edge_attr.size(0)  # 150998\n",
    "        g_edge = global_attr.unsqueeze(0).expand(E, -1)\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr,global_attr=g_edge)\n",
    "\n",
    "    def message(self,x_i, x_j,edge_attr,global_attr):\n",
    "        combined = torch.cat([x_i, x_j, edge_attr, global_attr], dim=-1)\n",
    "        return self.msg_mlp(combined)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        combined = torch.cat([x, aggr_out], dim=-1)\n",
    "        return self.upd_mlp(combined)"
   ],
   "id": "e6f1b7364b5b3000",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:42:17.014272Z",
     "start_time": "2026-02-05T14:42:17.007651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#using the message passing model\n",
    "\n",
    "class FlowPredictor(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels,num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = 10\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            self.layers.append(GNNMessagePassing(node_input=hidden_channels, edge_in=3, hidden_channels=hidden_channels, global_att_dim=2)) ## what sort of layers do we have in our module list.\n",
    "        self.encoder = nn.Linear(5, hidden_channels) # [x, y, u, v, p] -> 64\n",
    "#        self.processor = GNNMessagePassing(node_input=hidden_channels, edge_in=3, hidden_channels=hidden_channels)\n",
    "        self.decoder = nn.Linear(hidden_channels, 5) # hidden_channels -> [x, y, u, v, p]\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.encoder(data.x)\n",
    "        for layer in self.layers:\n",
    "            h_update = layer(h, data.edge_index, data.edge_attr, data.global_attr)\n",
    "\n",
    "        h = h + h_update\n",
    "        return self.decoder(h)\n",
    "\n",
    "    print(edge_attr.size())"
   ],
   "id": "6e1e56742bffd085",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150998, 3])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:42:25.525539Z",
     "start_time": "2026-02-05T14:42:18.983435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "global_attr_2 = global_attr_test.to(device)\n",
    "model = FlowPredictor(hidden_channels=64,num_layers=10).to(device)\n",
    "data = data.to(device)\n",
    "data_plus = data_plus.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.mse_loss(out, data.x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    avg_loss = total_loss / (epoch+1)\n",
    "    print(f\"Epoch {epoch+1:03d} | Average Loss: {avg_loss:.6f}\")\n"
   ],
   "id": "1fe7b9804882e40a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Average Loss: 26.200676\n",
      "Epoch 002 | Average Loss: 14.930766\n",
      "Epoch 003 | Average Loss: 26.217041\n",
      "Epoch 004 | Average Loss: 20.767680\n",
      "Epoch 005 | Average Loss: 18.248683\n",
      "Epoch 006 | Average Loss: 16.352998\n",
      "Epoch 007 | Average Loss: 14.757827\n",
      "Epoch 008 | Average Loss: 13.390655\n",
      "Epoch 009 | Average Loss: 12.192118\n",
      "Epoch 010 | Average Loss: 11.147276\n",
      "Epoch 011 | Average Loss: 10.250805\n",
      "Epoch 012 | Average Loss: 9.493711\n",
      "Epoch 013 | Average Loss: 8.836123\n",
      "Epoch 014 | Average Loss: 8.244492\n",
      "Epoch 015 | Average Loss: 7.719675\n",
      "Epoch 016 | Average Loss: 7.258993\n",
      "Epoch 017 | Average Loss: 6.850095\n",
      "Epoch 018 | Average Loss: 6.487181\n",
      "Epoch 019 | Average Loss: 6.161264\n",
      "Epoch 020 | Average Loss: 5.864366\n",
      "Epoch 021 | Average Loss: 5.592948\n",
      "Epoch 022 | Average Loss: 5.345402\n",
      "Epoch 023 | Average Loss: 5.119727\n",
      "Epoch 024 | Average Loss: 4.912862\n",
      "Epoch 025 | Average Loss: 4.721666\n",
      "Epoch 026 | Average Loss: 4.543887\n",
      "Epoch 027 | Average Loss: 4.378296\n",
      "Epoch 028 | Average Loss: 4.224170\n",
      "Epoch 029 | Average Loss: 4.080714\n",
      "Epoch 030 | Average Loss: 3.946914\n",
      "Epoch 031 | Average Loss: 3.821722\n",
      "Epoch 032 | Average Loss: 3.704179\n",
      "Epoch 033 | Average Loss: 3.593428\n",
      "Epoch 034 | Average Loss: 3.488835\n",
      "Epoch 035 | Average Loss: 3.389988\n",
      "Epoch 036 | Average Loss: 3.296553\n",
      "Epoch 037 | Average Loss: 3.208164\n",
      "Epoch 038 | Average Loss: 3.124422\n",
      "Epoch 039 | Average Loss: 3.044953\n",
      "Epoch 040 | Average Loss: 2.969424\n",
      "Epoch 041 | Average Loss: 2.897539\n",
      "Epoch 042 | Average Loss: 2.829022\n",
      "Epoch 043 | Average Loss: 2.763639\n",
      "Epoch 044 | Average Loss: 2.701188\n",
      "Epoch 045 | Average Loss: 2.641484\n",
      "Epoch 046 | Average Loss: 2.584354\n",
      "Epoch 047 | Average Loss: 2.529640\n",
      "Epoch 048 | Average Loss: 2.477210\n",
      "Epoch 049 | Average Loss: 2.426926\n",
      "Epoch 050 | Average Loss: 2.378644\n",
      "Epoch 051 | Average Loss: 2.332226\n",
      "Epoch 052 | Average Loss: 2.287562\n",
      "Epoch 053 | Average Loss: 2.244564\n",
      "Epoch 054 | Average Loss: 2.203151\n",
      "Epoch 055 | Average Loss: 2.163237\n",
      "Epoch 056 | Average Loss: 2.124743\n",
      "Epoch 057 | Average Loss: 2.087593\n",
      "Epoch 058 | Average Loss: 2.051715\n",
      "Epoch 059 | Average Loss: 2.017044\n",
      "Epoch 060 | Average Loss: 1.983524\n",
      "Epoch 061 | Average Loss: 1.951103\n",
      "Epoch 062 | Average Loss: 1.919729\n",
      "Epoch 063 | Average Loss: 1.889346\n",
      "Epoch 064 | Average Loss: 1.859906\n",
      "Epoch 065 | Average Loss: 1.831367\n",
      "Epoch 066 | Average Loss: 1.803691\n",
      "Epoch 067 | Average Loss: 1.776840\n",
      "Epoch 068 | Average Loss: 1.750777\n",
      "Epoch 069 | Average Loss: 1.725468\n",
      "Epoch 070 | Average Loss: 1.700880\n",
      "Epoch 071 | Average Loss: 1.676981\n",
      "Epoch 072 | Average Loss: 1.653744\n",
      "Epoch 073 | Average Loss: 1.631141\n",
      "Epoch 074 | Average Loss: 1.609148\n",
      "Epoch 075 | Average Loss: 1.587738\n",
      "Epoch 076 | Average Loss: 1.566891\n",
      "Epoch 077 | Average Loss: 1.546585\n",
      "Epoch 078 | Average Loss: 1.526799\n",
      "Epoch 079 | Average Loss: 1.507512\n",
      "Epoch 080 | Average Loss: 1.488706\n",
      "Epoch 081 | Average Loss: 1.470363\n",
      "Epoch 082 | Average Loss: 1.452466\n",
      "Epoch 083 | Average Loss: 1.434999\n",
      "Epoch 084 | Average Loss: 1.417948\n",
      "Epoch 085 | Average Loss: 1.401297\n",
      "Epoch 086 | Average Loss: 1.385033\n",
      "Epoch 087 | Average Loss: 1.369141\n",
      "Epoch 088 | Average Loss: 1.353610\n",
      "Epoch 089 | Average Loss: 1.338427\n",
      "Epoch 090 | Average Loss: 1.323580\n",
      "Epoch 091 | Average Loss: 1.309060\n",
      "Epoch 092 | Average Loss: 1.294854\n",
      "Epoch 093 | Average Loss: 1.280953\n",
      "Epoch 094 | Average Loss: 1.267348\n",
      "Epoch 095 | Average Loss: 1.254028\n",
      "Epoch 096 | Average Loss: 1.240985\n",
      "Epoch 097 | Average Loss: 1.228210\n",
      "Epoch 098 | Average Loss: 1.215696\n",
      "Epoch 099 | Average Loss: 1.203433\n",
      "Epoch 100 | Average Loss: 1.191415\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T14:42:30.497686Z",
     "start_time": "2026-02-05T14:42:30.041178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"lets put the model on eval mode now\"\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data_plus.y = data.x[:, 2:5].clone()\n",
    "    x_in = data_plus.x.clone()\n",
    "    x_in[:, 2:5] = 0.0\n",
    "\n",
    "    data_test_in = data_plus.clone()\n",
    "    data_test_in.x = x_in\n",
    "    data_test_in.global_attr = torch.tensor([1, 1000], device=device).float()\n",
    "\n",
    "    pred = model(data_test_in)\n",
    "\n",
    "test_loss = F.mse_loss(pred[:, 2:5], data_plus.y).item()\n",
    "rel = torch.norm(pred[:,2:5] - data_plus.y) / torch.norm(data_plus.y)\n",
    "print(\"Relative L2 error:\", rel.item())\n",
    "print(\"test mse:\", test_loss)"
   ],
   "id": "8c12ea6f9b8d39e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative L2 error: 1.6668188571929932\n",
      "test mse: 2.778284788131714\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T03:09:41.418936800Z",
     "start_time": "2026-02-04T19:41:04.014954Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "30e9cf51e57dccca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
